<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-03-15T00:10:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">lamttic’s playground</title><subtitle>data-analysis, machine-learning, recommender-system, and so on..</subtitle><author><name>lamttic</name></author><entry><title type="html">pandas를 효율적으로 사용하는 방법(2/2)</title><link href="http://localhost:4000/2020/03/11/01.html" rel="alternate" type="text/html" title="pandas를 효율적으로 사용하는 방법(2/2)" /><published>2020-03-11T18:11:00+09:00</published><updated>2020-03-11T18:11:00+09:00</updated><id>http://localhost:4000/2020/03/11/01</id><content type="html" xml:base="http://localhost:4000/2020/03/11/01.html">&lt;p&gt;&lt;a href=&quot;http://localhost:4000/2020/03/05/01.html&quot;&gt;지난 글&lt;/a&gt;에서는 pandas를 이용할 때 메모리 효율을 최적화 하기위한 방법에 대해서 알아보았다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 pandas 데이터를 어떻게 다루어야 빠르게 결과를 구할 수 있는지 알아보도록 한다.&lt;/p&gt;

&lt;h2 id=&quot;단순-반복을-피하자&quot;&gt;단순 반복을 피하자&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6&quot;&gt;A Beginner’s Guide to Optimizing Pandas Code for Speed&lt;/a&gt; 글을 보면, pandas dataframe의 처리 속도를 최적화하기 위한 방법에 대해 설명하고 있다.&lt;/p&gt;

&lt;p&gt;핵심은 비효율적인 반복을 피하고, 벡터화(vectorization)을 이용하라는 것인데, 이 글에서 설명하고 있는 방법을 차례대로 살펴보도록 하자.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6&quot;&gt;A Beginner’s Guide to Optimizing Pandas Code for Speed&lt;/a&gt; 글에서는 각 방법의 효율을 비교하기 위해 &lt;a href=&quot;https://en.wikipedia.org/wiki/Haversine_formula&quot;&gt;Haversine&lt;/a&gt; 수식을 이용했다.&lt;/p&gt;

&lt;p&gt;(Haversine 수식은 위도와 경도를 가진 두 좌표를 받아 지구의 곡률을 고려하여 두 좌표간의 직선거리를 계산하는 수식이다).&lt;/p&gt;

&lt;p&gt;테스트를 위한 샘플 데이터 및 jupyter notebook 코드는 &lt;a href=&quot;https://github.com/s-heisler/pycon2017-optimizing-pandas&quot;&gt;pycon2017-optimizing-pandas&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;1-forloop&quot;&gt;1. forloop&lt;/h4&gt;

&lt;p&gt;첫 번째 방법은 forloop을 이용한 단순 반복이다.&lt;/p&gt;

&lt;p&gt;단순 반복은 기존 python 객체와 동일하게 처리가능하기 때문에 쉽게 적용할 수 있지만 가장 느린 방법이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;haversine_looping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;distance_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;distance_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance_list&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;645 ms ± 31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;단순 반복을 이용하면 위와 같은 코드처럼 처리할 수 있다.&lt;/p&gt;

&lt;p&gt;1600개가 조금 넘는 행을 처리하는데 &lt;b&gt;645ms&lt;/b&gt;라는 매우 느린 실행속도를 보였다.&lt;/p&gt;

&lt;h4 id=&quot;2-iterrows-method&quot;&gt;2. iterrows method&lt;/h4&gt;

&lt;p&gt;두 번째 방법은 iterrows method를 이용하여 처리하는 방법이다.&lt;/p&gt;

&lt;p&gt;이 방법은 generator를 이용하여 각 행을 반환하고 dataframe에 사용할 수 있도록 최적화되어 있어 단순 반복보다는 효율적인 방법이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;haversine_series&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterrows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;haversine_series&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'distance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine_series&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;166 ms ± 2.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;iterrows method를 이용하면 &lt;b&gt;166ms&lt;/b&gt;로 기존 방법보다 4배 정도 빠르게 처리된 것을 확인할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;3-apply-method&quot;&gt;3. apply method&lt;/h4&gt;

&lt;p&gt;세 번째 방법은 apply method를 사용하는 것이다.&lt;/p&gt;

&lt;p&gt;apply method는 cython내 iterator를 사용하는 것과 같이 내부적인 최적화를 가져올 수 있어 기존의 방법들보다 더 효율적이다.&lt;/p&gt;

&lt;p&gt;주로 익명의 lambda 함수를 같이 사용하며, dataframe의 특정 영역을 함수의 입력 값으로 받고 axis 옵션을 주어 행과 열 데이터 중 원하는 데이터를 처리할 수 있다.&lt;/p&gt;

&lt;p&gt;apply method는 단순 반복이나 iterrows method와 동일한 횟수를 반복처리하지만 처리 속도는 확연하게 다르다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'distance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;90.6 ms ± 7.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 실행 결과를 보면 평균 &lt;b&gt;90.6ms&lt;/b&gt;로 두 번째 방법에 비해 2배 정도 빨라진 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;기억해야 할 것은 단순 반복, iterrows method, apply method은 모두 처리 방식의 차이가 있을 뿐 반복 횟수는 동일하는 것이다.&lt;/p&gt;

&lt;p&gt;이를 확인하기 위해 아래와 같이 &lt;b&gt;lprun&lt;/b&gt;이라는 명령어를 통해 처리 과정을 상세하게 볼 수 있다.&lt;/p&gt;

&lt;p&gt;(&lt;b&gt;lprun&lt;/b&gt; 명령어는 &lt;b&gt;timeit&lt;/b&gt;과 함께 pandas 처리과정을 최적화할 때 자주 확인해봐야 할 내용이니 참고하도록 하자.)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lprun&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-11-01-01.png&quot; alt=&quot;apply method의 lprun 실행 결과&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 실행 결과를 보면, 1631번의 반복 처리를 진행한 것을 알 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;4-pandas-series에-대한-벡터화-연산&quot;&gt;4. pandas series에 대한 벡터화 연산&lt;/h4&gt;

&lt;p&gt;pandas의 series는 인덱스와 값으로 이루어진 배열 기반의 객체이다.&lt;/p&gt;

&lt;p&gt;이러한 배열 기반의 데이터를 효과적으로 계산할 수 있는 방법이 벡터화(vectorization)인데, 벡터화는 배열 각각의 값(스칼라)에 대하여 반복적으로 데이터를 처리하지 않고, 배열 전체를 벡터로 변경하여 벡터 연산을 할 수 있게 해준다.&lt;/p&gt;

&lt;p&gt;pandas에서는 다양한 &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/index.html&quot;&gt;벡터화 함수&lt;/a&gt;를 지원하고 있으며, 이는 우리가 손쉽게 벡터화 함수를 사용할 수 있음을 의미한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'distance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;위의 예에서 보듯이, haversine 함수에 series(위도, 경도 열 데이터)를 제공하여 매우 간단하게 사용할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.62 ms ± 41.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 &lt;b&gt;1.62ms&lt;/b&gt;의 실행속도로 apply method에 비해 50배 이상 빠르게 처리되었고, 아래와 같이 해당 함수는 벡터화 연산을 단 한 번만 처리한 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-11-01-02.png&quot; alt=&quot;vectorization의 lprun 실행 결과&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이는 백터화 연산이 전달받은 배열을 스칼라 단위로 반복 처리한 것이 아니라 배열 단위로 벡터화하여 단 한 번의 연산으로 결과값을 구할 수 있음을 보여주는 것이다.&lt;/p&gt;

&lt;h4 id=&quot;5-numpy-배열에-대한-벡터화&quot;&gt;5. numpy 배열에 대한 벡터화&lt;/h4&gt;

&lt;p&gt;다섯 번째 방법은 numpy 배열을 벡터화하여 처리하는 것이다.&lt;/p&gt;

&lt;p&gt;사실 pandas series를 사용해서 벡터화하면 충분히 빠르게 요구사항을 처리할 수 있지만, 그 이상의 속도를 원한다면 numpy를 활용해야 한다.&lt;/p&gt;

&lt;p&gt;numpy는 미리 컴파일되어있는 c코드로 작업을 수행하기 때문에 더 빠르고 pandas series와 같은 배열 객체(ndarrays)를 이용한다.&lt;/p&gt;

&lt;p&gt;그리고 pandas에서 지원하는 기능(색인이나 데이터 타입 확인 등)을 제공하지 않는 대신 더 빠르게 작업을 수행한다.&lt;/p&gt;

&lt;p&gt;그렇기 때문에 pandas에서 지원하는 추가 기능이 필요할 때는 pandas series를 이용해야 한다.&lt;/p&gt;

&lt;p&gt;numpy 배열은 pandas series의 values method를 이용하여 바로 제공받을 수 있고 이를 통해 테스트를 진행한 결과는 아래와 같다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'distance'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;haversine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.671&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;73.985&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'latitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'longitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;370 µs ± 18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 결과를 보면, numpy 배열에 대한 벡터화를 이용하여 처리하면 pandas series를 이용할 때보다 약 4배 더 빠르게 결과를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;우리는 지금까지 pandas 처리속도를 올리기 위해 반복에 대해 처리할 수 있는 5가지 방법에 대하여 알아보았고, 이 중 단순 반복이나 iterrows method는 가급적 쓰지 않는 것이 좋고 최대한 벡터화를 이용하는 것이 좋다는 사실을 알았다.&lt;/p&gt;

&lt;p&gt;또한 최고 속도를 보였던 numpy 배열에 대한 백터화가 속도에는 가장 좋겠지만, pandas series에서 제공하는 기능을 사용해야 한다면 pandas series에 대한 벡터화만 해도 충분히 빠르다는 것을 알게 되었다.&lt;/p&gt;

&lt;h2 id=&quot;적절한-pandas-built-in-함수-활용&quot;&gt;적절한 pandas built-in 함수 활용&lt;/h2&gt;

&lt;p&gt;이제 반복에 대한 이야기를 정리하고 다음 이야기를 진행하고자 한다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;There should be one--and preferably only one--obvious way to do it. 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 문장은 python의 철학 중 하나이다.&lt;/p&gt;

&lt;p&gt;직역하면 &lt;b&gt;그것을 할 수 있는 분명한 한 가지 방법이 있어야 한다. 그 방법이 유일하다면 더 좋다.&lt;/b&gt; 정도로 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;python도 pandas도 처음 접할 때는 원하는 동작을 진행할 수 있는 방법이 다양하다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;하지만, 올바른 python 개발자는 주어진 상황에 최적의 방법을 찾아야 하고, python에 기초한 pandas 개발자도 이와 다르지 않다.&lt;/p&gt;

&lt;p&gt;pandas는 엄청나게 많은 method와 attribute를 제공한다.&lt;/p&gt;

&lt;p&gt;그 중 주어진 상황에서 최고의 효율을 낼 수 있는 method와 attribute를 사용하는 것이 중요하다.&lt;/p&gt;

&lt;p&gt;하나의 예를 들어보자.&lt;/p&gt;

&lt;p&gt;100만개의 점수가 들어있는 dataframe이 있다고 가정하고 이 중 가장 큰 값을 가진 5개만 추출하는 방법에 대해 개발해야 한다면 어떨까?&lt;/p&gt;

&lt;p&gt;어떤 개발자는 sort_values와 head method를 이용하여 개발할 수 있고, 어떤 개발자는 nlargest method를 이용할지 모른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-11-01-03.png&quot; alt=&quot;nlargest 실행 결과&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2가지 처리 방식은 동일한 결과를 같지만 8배에 가까운 처리 속도 차이를 보여주는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;pandas 개발자는 결국 더 빨리 결과물을 얻기 위해서 최적의 방법을 찾아야한다.&lt;/p&gt;

&lt;p&gt;아쉽게도 원하는 요구사항과 상황이 달라 모든 정답을 가지고 있을 수 없기에 &lt;a href=&quot;https://www.machinelearningplus.com/python/101-pandas-exercises-python/&quot;&gt;pandas-101&lt;/a&gt;, &lt;a href=&quot;https://github.com/rougier/numpy-100&quot;&gt;numpy-100&lt;/a&gt;과 같이 여러가지 pandas, numpy 문제에 해결책을 제시한 곳을 참고하는 것도 좋은 방법이다.&lt;/p&gt;

&lt;h2 id=&quot;마치며&quot;&gt;마치며&lt;/h2&gt;

&lt;p&gt;이 글에서는 pandas를 효율적으로 처리하는 방법 중 속도를 개선할 수 있는 방법에 대해 살펴보았다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;반복처리가 필요할 때는 단순 반복이나 iterrows method 보다는 벡터화를 이용하여 처리하는 것이 더 빠르다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;요구사항을 만족하더라도 속도를 더 개선시킬 수 있도록 다른 built-in method가 없는지 확인하자.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>lamttic</name></author><summary type="html">지난 글에서는 pandas를 이용할 때 메모리 효율을 최적화 하기위한 방법에 대해서 알아보았다.</summary></entry><entry><title type="html">elasticsearch에서 nori, ngram tokenizer를 동시에 활용하기</title><link href="http://localhost:4000/2020/03/10/01.html" rel="alternate" type="text/html" title="elasticsearch에서 nori, ngram tokenizer를 동시에 활용하기" /><published>2020-03-10T16:07:00+09:00</published><updated>2020-03-10T16:07:00+09:00</updated><id>http://localhost:4000/2020/03/10/01</id><content type="html" xml:base="http://localhost:4000/2020/03/10/01.html">&lt;p&gt;elasticsearch는 최근 가장 많이 사용되고 있는 검색 및 분석 엔진 서비스로 빠른 속도, 쉬운 확장성과 같은 장점때문에 많이 사용되고 있다.&lt;/p&gt;

&lt;p&gt;보통 검색엔진으로 사용하는 경우, tokenizer를 이용하여 token을 색인하는데, 어떤 tokenizer를 활용하냐에 따라 검색의 방향과 품질에 정해진다.&lt;/p&gt;

&lt;p&gt;이 중 nori tokenizer는 잘 알려진 한글 tokenizer로써, 사용자 사전과 함께 사용하면 좋은 성능을 보인다.&lt;/p&gt;

&lt;p&gt;하지만, nori tokenizer나 사용자 사전에서 인식하지 못하는 형태소나 부분적으로 포함된 키워드가 있을 경우 검색 결과에서 볼 수 없는 문제가 있다.&lt;/p&gt;

&lt;p&gt;이 글에서는 nori tokenizer와 ngram tokenizer를 같이 활용하여 검색 품질을 높일 수 방법에 대해 알아보고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;문제점-및-개선방향&quot;&gt;문제점 및 개선방향&lt;/h2&gt;

&lt;p&gt;그동안 개발하고 있는 서비스에서는 elasticsearch에 nori tokenizer를 활용했다.&lt;/p&gt;

&lt;p&gt;(nori tokenizer에 약 20만개의 사용자 사전과 동의어, 불용어 사전을 붙여 사용했다.)&lt;/p&gt;

&lt;p&gt;이 방법은 사전 정보가 잘 구성이 되어 있을 때는 성능이 좋지만 사전이 부족하거나 정제되지 않는 키워드가 많은 경우 검색이 잘 되지 않는 문제가 있었다.&lt;/p&gt;

&lt;p&gt;(사용자가 직접 컨텐츠를 생산하는 경우, 정제되지 않은 키워드가 포함될 가능성이 높으므로 예측하지 못한 단어 사용이 늘어나 문제가 발생될 확률이 높다.)&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해 아래의 조건을 만족하면서 LIKE 검색과 유사하게 동작할 수 있는 방법을 찾아야 했다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;nori tokenizer로 색인하는 방법과 병행할 수 있는 방법이어야 한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;검색 속도 및 성능에 지장이 있어서는 안된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;우선, 기존 nori tokenizer로 색인하여 검색하는 방법의 성능이 어느정도 보장이 되었기 때문에 기존의 성능은 유지하면서 개선할 수 있어야 한다.&lt;/p&gt;

&lt;p&gt;또한, 새로운 방법을 적용한다고 해도 검색엔진 속도나 성능에 문제가 생기지 않아야 한다.&lt;/p&gt;

&lt;h2 id=&quot;새로운-필드-생성-그리고-wildcard-쿼리&quot;&gt;새로운 필드 생성 그리고 wildcard 쿼리&lt;/h2&gt;

&lt;p&gt;우선, 첫 번째 조건을 만족하기 위해 가장 먼저 떠오른 아이디어는 wildcard 쿼리를 사용하는 것이었다.&lt;/p&gt;

&lt;p&gt;wildcard는 sql의 LIKE 쿼리와 같이 특정 키워드가 포함된 모든 결과를 찾을 수 있어서 원하는 동작을 할 수 있다고 생각했다.&lt;/p&gt;

&lt;p&gt;테스트를 위해 애국가 앞 부분을 nori tokenizer를 이용하여 추출된 결과는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPOST http://localhost:9200/test/_analyze?pretty -H 'content-type: application/json' -d '
{
  &quot;analyzer&quot;: &quot;nori_analyzer&quot;,
  &quot;text&quot;: &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;
}

{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;동해&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 2,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;물&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 3,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;백두&quot;,
      &quot;start_offset&quot; : 5,
      &quot;end_offset&quot; : 7,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;산&quot;,
      &quot;start_offset&quot; : 7,
      &quot;end_offset&quot; : 8,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 4
    },
    {
      &quot;token&quot; : &quot;마르&quot;,
      &quot;start_offset&quot; : 10,
      &quot;end_offset&quot; : 12,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 6
    },
    {
      &quot;token&quot; : &quot;닳&quot;,
      &quot;start_offset&quot; : 14,
      &quot;end_offset&quot; : 15,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 8
    },
    {
      &quot;token&quot; : &quot;하느&quot;,
      &quot;start_offset&quot; : 18,
      &quot;end_offset&quot; : 20,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 10
    },
    {
      &quot;token&quot; : &quot;님&quot;,
      &quot;start_offset&quot; : 20,
      &quot;end_offset&quot; : 21,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 11
    },
    {
      &quot;token&quot; : &quot;보우&quot;,
      &quot;start_offset&quot; : 23,
      &quot;end_offset&quot; : 25,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 13
    },
    {
      &quot;token&quot; : &quot;우리&quot;,
      &quot;start_offset&quot; : 28,
      &quot;end_offset&quot; : 30,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 16
    },
    {
      &quot;token&quot; : &quot;나라&quot;,
      &quot;start_offset&quot; : 30,
      &quot;end_offset&quot; : 32,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 17
    },
    {
      &quot;token&quot; : &quot;만세&quot;,
      &quot;start_offset&quot; : 33,
      &quot;end_offset&quot; : 35,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 18
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 nori tokenizer로 색인한 문서 중 &lt;b&gt;백두&lt;/b&gt;가 포함된 검색결과를 얻기 위해 wildcard로 검색하면 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XGET http://localhost:9200/test/_search?pretty -H 'content-type: application/json' -d '
{
  &quot;query&quot;: {
    &quot;wildcard&quot;: {
      &quot;nori&quot;: {
        &quot;value&quot;: &quot;*백두*&quot;
      }
    }
  }
}
'

{
  &quot;took&quot; : 1,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : {
      &quot;value&quot; : 1,
      &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 1.0,
    &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 1.0,
        &quot;_source&quot; : {
          &quot;text&quot; : &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그렇다면 다음의 예를 살펴보자.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XGET http://localhost:9200/test/_search?pretty -H 'content-type: application/json' -d '
{
  &quot;query&quot;: {
    &quot;wildcard&quot;: {
      &quot;nori&quot;: {
        &quot;value&quot;: &quot;*닳도*&quot;
      }
    }
  }
}
'

{
  &quot;took&quot; : 1,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : {
      &quot;value&quot; : 0,
      &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : null,
    &quot;hits&quot; : [ ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 예를 보면, 본문에 &lt;b&gt;닳도록&lt;/b&gt;이라는 문자열이 있어서 &lt;b&gt;닳도&lt;/b&gt;라는 검색어로 검색될 것으로 생각할 수 있지만 이미 &lt;b&gt;닳&lt;/b&gt;이라는 token으로 분해되어 색인이 되었기 때문에 원하는대로 동작하지 않는다.&lt;/p&gt;

&lt;p&gt;이 예시를 통해 wildcard를 사용하더라도 기존 필드는 유지하고 새로운 필드에 다른 tokenizer를 이용하여 색인을 하는 것이 바람직하다고 느꼈다.&lt;/p&gt;

&lt;p&gt;색인하는 필드를 늘리게 되면 저장공간을 더 많이 필요로 하고 색인 속도가 느려진다는 단점이 있지만, nori를 이용하여 색인하는 기존 필드는 변하지 않기 때문에 검색 결과가 줄어서 품질이 떨어질 확률은 없다고 생각했다.&lt;/p&gt;

&lt;p&gt;(물론, 원하지 않는 검색결과가 노출되어 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80_%EC%9E%AC%ED%98%84%EC%9C%A8&quot;&gt;precision&lt;/a&gt;이 감소할 수 있지만 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80_%EC%9E%AC%ED%98%84%EC%9C%A8&quot;&gt;recall&lt;/a&gt;이 올라갈 것이기 때문에, 검색어 상태에 따라 검색해야 할 필드를 지정하면 큰 문제가 되지 않을 것이라고 판단했다.)&lt;/p&gt;

&lt;p&gt;또한, wildcard를 &lt;b&gt;*질의어*&lt;/b&gt;와 같이 쓰게 되면 원하는 키워드를 찾기 위해 반복하는 과정이 늘어날 수 있다고 &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html#wildcard-query-field-params&quot;&gt;경고&lt;/a&gt;하고 있기 때문에 다른 방법을 찾아야 했다.&lt;/p&gt;

&lt;h2 id=&quot;ngram-tokenizer-추가&quot;&gt;ngram tokenizer 추가&lt;/h2&gt;

&lt;p&gt;새로운 필드에 색인을 한다고 해도 wildcard와 같이 쿼리 레벨에서 처리할 수 없다면, LIKE 검색과 유사하게 색인할 수 있는 tokenizer가 필요했다.&lt;/p&gt;

&lt;p&gt;이러한 문제를 해결할 수 있는 ngram tokenizer가 있는데, ngram은 자연어 처리를 조금이라도 해보았다면 한 번쯤 들어봤을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-10-01-01.png&quot; alt=&quot;ngram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림을 보면 ngram에 대해 쉽게 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;ngram은 n개의 인접 단어를 추출하여 학습이나 분석에 사용하는데, n=1인 경우 첫 번째 항목처럼 unigram이라 불리우고 각 단어 1개씩을 추출한다.&lt;/p&gt;

&lt;p&gt;n=2인 경우는 bigram이라 하고 &lt;b&gt;this is&lt;/b&gt;, &lt;b&gt;is a&lt;/b&gt;와 같이 2개씩 묶어서 추출한다.&lt;/p&gt;

&lt;p&gt;이렇게 추출된 ngram은 인접한 단어 패턴을 분석하여 문서의 종류를 분류하거나 문서를 조합할 때 쓰인다.&lt;/p&gt;

&lt;p&gt;ngram을 활용한 tokenizer는 term 레벨에서 ngram을 추출하게 되는데, 단어가 아닌 문자 단위로 추출한다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPUT http://localhost:9200/test -H 'content-type: application/json' -d '
{
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;analysis&quot;: {
        &quot;analyzer&quot;: {
          &quot;ngram_analyzer&quot;: {
            &quot;type&quot;: &quot;custom&quot;,
            &quot;tokenizer&quot;: &quot;my_ngram&quot;
          }
        },
        &quot;tokenizer&quot;: {
          &quot;my_ngram&quot;: {
            &quot;type&quot;: &quot;ngram&quot;,
            &quot;min_gram&quot;: 2,
            &quot;max_gram&quot;: 2,
            &quot;token_chars&quot;: [
              &quot;letter&quot;,
              &quot;digit&quot;
            ]
          }
        }
      }
    }
  }
}
'

curl -XPOST http://localhost:9200/test/_analyze?pretty -H 'content-type: application/json' -d '
{
  &quot;analyzer&quot;: &quot;ngram_analyzer&quot;,
  &quot;text&quot;: &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;
}
'

{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;동해&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 2,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;해물&quot;,
      &quot;start_offset&quot; : 1,
      &quot;end_offset&quot; : 3,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;물과&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 4,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 2
    },
    {
      &quot;token&quot; : &quot;백두&quot;,
      &quot;start_offset&quot; : 5,
      &quot;end_offset&quot; : 7,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 3
    },
    {
      &quot;token&quot; : &quot;두산&quot;,
      &quot;start_offset&quot; : 6,
      &quot;end_offset&quot; : 8,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 4
    },
    {
      &quot;token&quot; : &quot;산이&quot;,
      &quot;start_offset&quot; : 7,
      &quot;end_offset&quot; : 9,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 5
    },
    {
      &quot;token&quot; : &quot;마르&quot;,
      &quot;start_offset&quot; : 10,
      &quot;end_offset&quot; : 12,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 6
    },
    {
      &quot;token&quot; : &quot;르고&quot;,
      &quot;start_offset&quot; : 11,
      &quot;end_offset&quot; : 13,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 7
    },
    {
      &quot;token&quot; : &quot;닳도&quot;,
      &quot;start_offset&quot; : 14,
      &quot;end_offset&quot; : 16,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 8
    },
    {
      &quot;token&quot; : &quot;도록&quot;,
      &quot;start_offset&quot; : 15,
      &quot;end_offset&quot; : 17,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 9
    },
    {
      &quot;token&quot; : &quot;하느&quot;,
      &quot;start_offset&quot; : 18,
      &quot;end_offset&quot; : 20,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 10
    },
    {
      &quot;token&quot; : &quot;느님&quot;,
      &quot;start_offset&quot; : 19,
      &quot;end_offset&quot; : 21,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 11
    },
    {
      &quot;token&quot; : &quot;님이&quot;,
      &quot;start_offset&quot; : 20,
      &quot;end_offset&quot; : 22,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 12
    },
    {
      &quot;token&quot; : &quot;보우&quot;,
      &quot;start_offset&quot; : 23,
      &quot;end_offset&quot; : 25,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 13
    },
    {
      &quot;token&quot; : &quot;우하&quot;,
      &quot;start_offset&quot; : 24,
      &quot;end_offset&quot; : 26,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 14
    },
    {
      &quot;token&quot; : &quot;하사&quot;,
      &quot;start_offset&quot; : 25,
      &quot;end_offset&quot; : 27,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 15
    },
    {
      &quot;token&quot; : &quot;우리&quot;,
      &quot;start_offset&quot; : 28,
      &quot;end_offset&quot; : 30,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 16
    },
    {
      &quot;token&quot; : &quot;리나&quot;,
      &quot;start_offset&quot; : 29,
      &quot;end_offset&quot; : 31,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 17
    },
    {
      &quot;token&quot; : &quot;나라&quot;,
      &quot;start_offset&quot; : 30,
      &quot;end_offset&quot; : 32,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 18
    },
    {
      &quot;token&quot; : &quot;만세&quot;,
      &quot;start_offset&quot; : 33,
      &quot;end_offset&quot; : 35,
      &quot;type&quot; : &quot;word&quot;,
      &quot;position&quot; : 19
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 예를 살펴보면, bigram(2gram)을 추출하여 &lt;b&gt;동해&lt;/b&gt;, &lt;b&gt;해물&lt;/b&gt;, &lt;b&gt;물과&lt;/b&gt;와 같이 2개씩 묶여 색인한 결과를 볼 수 있다.&lt;/p&gt;

&lt;p&gt;(질의어 패턴을 보았을 때 bigram만으로 충분히 LIKE 검색과 유사하게 사용할 수 있다고 생각했다. 적용하고자 하는 검색 서비스 특성에 따라  unigram(1gram), trigram(3gram)과 같은 다양한 ngram을 활용할 수 있다.)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XGET http://localhost:9200/test/_search?pretty -H 'content-type: application/json' -d '
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;: &quot;닳도&quot;,
      &quot;fields&quot;: [ &quot;ngram&quot; ]
    }
  }
}
'

{
  &quot;took&quot; : 0,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : {
      &quot;value&quot; : 1,
      &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 0.2876821,
    &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 0.2876821,
        &quot;_source&quot; : {
          &quot;nori&quot; : &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;,
          &quot;ngram&quot; : &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 ngram tokenizer를 이용하면 색인된 문서를 단순 쿼리로 검색할 수 있다.&lt;/p&gt;

&lt;p&gt;또한, 아래와 같이 nori, ngram 필드 모두에 대해서도 원하는 검색결과를 얻을 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XGET http://localhost:9200/test/_search?pretty -H 'content-type: application/json' -d '
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;: &quot;백두&quot;,
      &quot;fields&quot;: [ &quot;nori&quot;, &quot;ngram&quot; ]
    }
  }
}
'

{
  &quot;took&quot; : 1,
  &quot;timed_out&quot; : false,
  &quot;_shards&quot; : {
    &quot;total&quot; : 1,
    &quot;successful&quot; : 1,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  },
  &quot;hits&quot; : {
    &quot;total&quot; : {
      &quot;value&quot; : 1,
      &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 0.8630463,
    &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 0.8630463,
        &quot;_source&quot; : {
          &quot;nori&quot; : &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;,
          &quot;ngram&quot; : &quot;동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세&quot;
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;지금까지 nori tokenizer와 ngram tokenizer를 활용하여 사전 및 LIKE 검색을 동시에 처리하는 방법에 대하여 알아보았다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;nori tokenizer 색인&lt;/li&gt;
  &lt;li&gt;별도의 필드에 ngram tokenizer를 이용하여 색인&lt;/li&gt;
  &lt;li&gt;두 필드에 대해 multi match query 사용&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;간단히 정리하면, 위 3가지 과정을 거치면 쉽게 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;단, 이 방법은 무조건적인 성능 개선이 아니기 때문에(recall은 증가시키고 precision을 감소시킬 수 있기 때문에) 검색 서비스의 특성을 고려하여 반영하는 것이 바람직해보인다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">elasticsearch는 최근 가장 많이 사용되고 있는 검색 및 분석 엔진 서비스로 빠른 속도, 쉬운 확장성과 같은 장점때문에 많이 사용되고 있다.</summary></entry><entry><title type="html">macOS에서 pyexpat 모듈 못찾는 문제 해결</title><link href="http://localhost:4000/2020/03/07/01.html" rel="alternate" type="text/html" title="macOS에서 pyexpat 모듈 못찾는 문제 해결" /><published>2020-03-07T18:33:00+09:00</published><updated>2020-03-07T18:33:00+09:00</updated><id>http://localhost:4000/2020/03/07/01</id><content type="html" xml:base="http://localhost:4000/2020/03/07/01.html">&lt;p&gt;macOS에서 pyenv install 시 아래와 같은 메시지와 함께 설치가 안되는 문제가 발생하는 경우가 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~ » pyenv install 3.8.1
Installing openssl-1.1.0j...
Installed openssl-1.1.0j to /Users/charles/.pyenv/versions/3.8.1

python-build: use readline from homebrew
Installing Python-3.8.1...
python-build: use readline from homebrew
python-build: use zlib from xcode sdk

BUILD FAILED (OS X 10.14.3 using python-build 20180424)

Inspect or clean up the working tree at /var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/python-build.20200307180551.1839
Results logged to /var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/python-build.20200307180551.1839.log

Last 10 log lines:
  File &quot;&amp;lt;frozen zipimport&amp;gt;&quot;, line 259, in load_module
  File &quot;/var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/tmpnzts9bjh/pip-19.2.3-py2.py3-none-any.whl/pip/_internal/utils/misc.py&quot;, line 21, in &amp;lt;module&amp;gt;
  File &quot;&amp;lt;frozen zipimport&amp;gt;&quot;, line 259, in load_module
  File &quot;/var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/tmpnzts9bjh/pip-19.2.3-py2.py3-none-any.whl/pip/_vendor/pkg_resources/__init__.py&quot;, line 35, in &amp;lt;module&amp;gt;
  File &quot;/private/var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/python-build.20200307180551.1839/Python-3.8.1/Lib/plistlib.py&quot;, line 65, in &amp;lt;module&amp;gt;
    from xml.parsers.expat import ParserCreate
  File &quot;/private/var/folders/tf/x42t0bkd7tq356r84rsbc3fm0000gn/T/python-build.20200307180551.1839/Python-3.8.1/Lib/xml/parsers/expat.py&quot;, line 4, in &amp;lt;module&amp;gt;
    from pyexpat import *
ModuleNotFoundError: No module named 'pyexpat'
make: *** [install] Error 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 경우 &lt;a href=&quot;https://github.com/pyenv/pyenv/issues/1066&quot;&gt;해결책&lt;/a&gt; 링크를 참고하여 아래와 같이 해결할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo rm -rf /Library/Developer/CommandLineTools
xcode-select --install
pkgutil --pkg-info=com.apple.pkg.CLTools_Executables
pyenv install 3.8.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-07-01-01.png&quot; alt=&quot;처리 결과&quot; /&gt;&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">macOS에서 pyenv install 시 아래와 같은 메시지와 함께 설치가 안되는 문제가 발생하는 경우가 있다.</summary></entry><entry><title type="html">pandas를 효율적으로 사용하는 방법(1/2)</title><link href="http://localhost:4000/2020/03/05/01.html" rel="alternate" type="text/html" title="pandas를 효율적으로 사용하는 방법(1/2)" /><published>2020-03-05T22:35:00+09:00</published><updated>2020-03-05T22:35:00+09:00</updated><id>http://localhost:4000/2020/03/05/01</id><content type="html" xml:base="http://localhost:4000/2020/03/05/01.html">&lt;p&gt;python을 이용하여 데이터 분석을 하는 사람이라면 pandas는 가장 많이 애용하는 라이브러리 중 하나일 것이다.&lt;/p&gt;

&lt;p&gt;pandas는 쉽고 빠르지만 최적화를 진행하지 않고 사용하다가는 memory overflow가 발생하거나 크지 않은 데이터를 처리하면서 하염없이 작업이 끝나기를 기다리는 자신을 발견할지 모른다.&lt;/p&gt;

&lt;p&gt;이 글에서는 pandas에서 메모리를 효율적으로 사용할 수 있는 방법에 대하여 설명한다.&lt;/p&gt;

&lt;p&gt;pandas에서 데이터를 처리하다보면 적게는 수백 개부터 많게는 수천만, 수억 개 이상의 데이터를 처리해야 한다.&lt;/p&gt;

&lt;p&gt;당연한 이야기이겠지만 이 데이터들은 각자 메모리 공간을 차지하므로 너무 많은 메모리를 차지하면 memory overflow가 발생하거나 비효율적인 계산을 하게 된다.&lt;/p&gt;

&lt;p&gt;이를 방지하기 위해 메모리 공간 사용을 최소화하도록 다양한 방법을 활용할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-전처리-역할-분담&quot;&gt;데이터 전처리 역할 분담&lt;/h2&gt;

&lt;p&gt;pandas는 데이터 저장소로부터 기초 데이터(raw data)를 불러와서 새로운 데이터로 가공하여 결과물을 만들어내는 작업에 많이 사용한다.&lt;/p&gt;

&lt;p&gt;하지만, 기초 데이터의 양이 많을수록 엄청난 IO 부담과 시간 비용이 늘어나게 되고, 이러한 데이터를 가공할 때 많은 리소스를 필요로 하게 된다.&lt;/p&gt;

&lt;p&gt;상황에 따라 pandas에서 기초 데이터를 이용하여 다양한 결과물을 만들어낼 수 있지만, 무조건 기초 데이터를 이용하여 처리를 할 필요는 없다.&lt;/p&gt;

&lt;p&gt;오히려, aggreate가 가능한 빅데이터 플랫폼을 이용하고 있다면, 기본적인 전처리는 pandas에서 직접하는 것보다 해당 플랫폼에서 처리하여 제공받는 것이 빠르고 효율적일 경우가 많다.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;(보통 처리 속도도 차이가 나지만, 많은 양의 IO 때문에 데이터를 가져오는 시간이 꽤 소요되는 경우가 많다.)&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;또한, 빅데이터 플랫폼에서 전처리하는 과정 중에 일부 feature engineering을 해줄 수 있기 때문에 pandas에서 사용해야 하는 메모리를 최소화할 수 있고, 계산 또한 빠르게 처리할 수 있다.&lt;/p&gt;

&lt;p&gt;만약, 회사에서 직접 대용량 데이터 처리를 위한 빅데이터 플랫폼을 구축하기 부담스럽다면, 구글의 BigQuery나 Arm의 TreasureData 와 같은 서비스를 이용하는 것을 추천한다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-형식-최적화&quot;&gt;데이터 형식 최적화&lt;/h2&gt;

&lt;p&gt;pandas에서 처리할 수 있는 데이터 형식(dtype)은 &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#dtypes&quot;&gt;pandas dtypes 설명&lt;/a&gt; 링크를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;링크의 내용을 살펴보면, pandas에서 지원하는 데이터 형식에는 numpy에서 지원하는 float, int, bool, datetime64 이외에도 category, string, object 형식 등 다양한 데이터 형식이 있는데 데이터 형식은 종류에 따라 가질 수 있는 값의 범위가 다르고 당연히 메모리 사용공간에 차이가 있다.&lt;/p&gt;

&lt;p&gt;따라서, 처리하고자 하는 데이터가 가지고 있는 값의 범위에 따라 최적화된 데이터 형식을 지정해주어야 불필요한 메모리 사용량을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;유사한 데이터 형식을 최적화하기 위해서는 아래의 코드를 참고하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def get_ideal_dtypes(df):
    ideal_dtypes = dict()
    
    for column in df.columns:
        dtype = df[column].dtype
        
        if dtype != object:
            c_min = df[column].min()
            c_max = df[column].max()

            # 숫자형 데이터 형식 최적화
            if str(dtype)[:3] == 'int':
                if c_min &amp;gt; np.iinfo(np.int8).min and c_max &amp;lt; np.iinfo(np.int8).max:
                    ideal_dtypes[column] = 'int8'
                elif c_min &amp;gt; np.iinfo(np.uint8).min and c_max &amp;lt; np.iinfo(np.uint8).max:
                    ideal_dtypes[column] = 'uint8'
                elif c_min &amp;gt; np.iinfo(np.int16).min and c_max &amp;lt; np.iinfo(np.int16).max:
                    ideal_dtypes[column] = 'int16'
                elif c_min &amp;gt; np.iinfo(np.uint16).min and c_max &amp;lt; np.iinfo(np.uint16).max:
                    ideal_dtypes[column] = 'uint16'
                elif c_min &amp;gt; np.iinfo(np.int32).min and c_max &amp;lt; np.iinfo(np.int32).max:
                    ideal_dtypes[column] = 'int32'
                elif c_min &amp;gt; np.iinfo(np.uint32).min and c_max &amp;lt; np.iinfo(np.uint32).max:
                    ideal_dtypes[column] = 'uint32'
                elif c_min &amp;gt; np.iinfo(np.int64).min and c_max &amp;lt; np.iinfo(np.int64).max:
                    ideal_dtypes[column] = 'int64'
                elif c_min &amp;gt; np.iinfo(np.uint64).min and c_max &amp;lt; np.iinfo(np.uint64).max:
                    ideal_dtypes[column] = 'uint64'
            else:
                if c_min &amp;gt; np.finfo(np.float16).min and c_max &amp;lt; np.finfo(np.float16).max:
                    ideal_dtypes[column] = 'float16'
                elif c_min &amp;gt; np.finfo(np.float32).min and c_max &amp;lt; np.finfo(np.float32).max:
                    ideal_dtypes[column] = 'float32'
                else:
                    ideal_dtypes[column] = 'float64'
        else:
            n_unique = df[column].nunique()
            
            # 값의 종류가 n개 미만일 경우에만 category 형식으로 최적화
            if n_unique &amp;gt; n:
                ideal_dtypes[column] = 'object'
            else:
                ideal_dtypes[column] = 'category'
            
    return ideal_dtypes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 코드에서는 숫자형 데이터 형식은 각 컬럼의 min, max값으로 범위를 구하여 최적의 데이터 형식을 찾아준다.&lt;/p&gt;

&lt;p&gt;그리고 object 데이터 형식이 특정 값들로 반복될 때, category 데이터 형식을 권장한다.&lt;/p&gt;

&lt;p&gt;이 방법을 이용하면, 아래와 같이 24MB의 데이터를 7MB까지 줄일 정도로 큰 효과를 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-05-01-01.png&quot; alt=&quot;데이터 형식 최적화 예시&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;코드화&quot;&gt;코드화&lt;/h2&gt;

&lt;p&gt;데이터 형식 최적화가 최적화된 데이터 형식을 찾아내는 것이었다면, 코드화는 사람이 알아보기 쉬운 값을 컴퓨터가 사용하기 용이한 형태로 변경하는 작업이다. 쉬운 예로, 성별, 지역 등과 같이 구분되어지는(discrete) 문자열(String) 을 0,1과 같은 숫자로 변경하는 과정을 들 수 있다.&lt;/p&gt;

&lt;p&gt;이 방법은 메모리 최적화를 진행할 수 있는 방법 중 가장 쉽게 사용 메모리를 줄일 수 있는 방법이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2020-03-05-01-02.png&quot; alt=&quot;코드화 예시&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같이 category 형식과 코드화는 메모리 크기가 동일하므로(둘다 int8) 가독성이 좋은 category를 이용하는 것이 더 낫긴 하다.&lt;/p&gt;

&lt;h2 id=&quot;불필요한-데이터-필터링&quot;&gt;불필요한 데이터 필터링&lt;/h2&gt;

&lt;p&gt;pandas에서 사용하는 데이터들을 살펴보면 불필요한 값들이 남아있는 경우가 많다. 이런 불필요한 데이터들은 필터링을 진행하고 데이터 처리를 하는 것이 좋다.&lt;/p&gt;

&lt;p&gt;일례로 데이터를 처리하고나서 필요없어진 데이터나 비정상적인 값들로 판단되어 처리대상이 아닌 데이터가 있는 경우 제거하는 것이 좋다. 또한, 부분적으로 필요한 열이나 행 데이터만 가져와서 처리를 한다거나, python generator를 이용하여 원하는 크기만큼 데이터를 가져와서 처리할 수도 있다.&lt;/p&gt;

&lt;p&gt;이는 데이터를 제공한 도메인에 대한 관련 지식이 있는 사람이 처리를 하는 것이 바람직하다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:4000/2020/03/10/01.html&quot;&gt;다음 글&lt;/a&gt;에서는 pandas를 효율적으로 사용하는 방법 중 효율적인 데이터 처리 방식에 대해 설명하고자 한다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">python을 이용하여 데이터 분석을 하는 사람이라면 pandas는 가장 많이 애용하는 라이브러리 중 하나일 것이다.</summary></entry><entry><title type="html">keras를 이용한 다중 클래스 이미지 분류(2/2)</title><link href="http://localhost:4000/2017/01/05/01.html" rel="alternate" type="text/html" title="keras를 이용한 다중 클래스 이미지 분류(2/2)" /><published>2017-01-05T21:36:00+09:00</published><updated>2017-01-05T21:36:00+09:00</updated><id>http://localhost:4000/2017/01/05/01</id><content type="html" xml:base="http://localhost:4000/2017/01/05/01.html">&lt;p&gt;이 글은 이전 글인 &lt;a href=&quot;http://localhost:4000/2017/01/04/01.html&quot;&gt;keras를 이용한 다중 클래스 이미지 분류&lt;/a&gt;에 이어서 작성되었다.&lt;/p&gt;

&lt;p&gt;이전 글에서 기 학습된 모델의 feature를 활용하여 top_model을 학습하는 것에 대해 설명하였다면, 이 글에서는 fine tuning을 통해 마지막 레이어를 세밀하게 학습하는 과정을 살펴보도록 하자.&lt;/p&gt;

&lt;h2 id=&quot;fine-tuning&quot;&gt;Fine tuning&lt;/h2&gt;

&lt;p&gt;이전 글에서 설명했듯이, fine tuning은 미리 학습된 모델의 마지막 레벨 conv block의 weights를 학습하되 새로운 훈련 예를 이용하여 weights를 조금씩 갱신하는 것이다.&lt;/p&gt;

&lt;p&gt;fine tuning을 진행하면, overfitting 문제를 줄일 수 있고, 주어진 훈련 예에 맞는 feature들에 대해 세밀한 학습이 이뤄질 수 있다.&lt;/p&gt;

&lt;p&gt;아래 코드는, &lt;a href=&quot;http://localhost:4000/2017/01/04/01.html&quot;&gt;keras를 이용한 다중 클래스 이미지 분류&lt;/a&gt;에서 기 학습된 weights와 &lt;a href=&quot;https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975&quot;&gt;keras 이진 분류 fine tuning 샘플 코드&lt;/a&gt;를 활용하여 생성한 샘플 코드의 일부분이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# build a classifier model to put on top of the convolutional model             
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                                                        
&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt;                      
&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                                    
&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                                                     
&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                        
                                                                                
&lt;span class=&quot;c1&quot;&gt;# note that it is necessary to start with a fully-trained                       
# classifier, including the top classifier,                                     
# in order to successfully do fine-tuning                                       
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_model_weights_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                  
                                                                                
&lt;span class=&quot;c1&quot;&gt;# add the model on top of the convolutional base                                
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                                            
                                                                                
&lt;span class=&quot;c1&quot;&gt;# set the first 25 layers (up to the last conv block)                           
# to non-trainable (weights will not be updated)                                
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;                                                 
    &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;     

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# prepare data augmentation configuration
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_datagen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rescale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rotation_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;width_shift_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;height_shift_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shear_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zoom_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;horizontal_flip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fill_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nearest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_datagen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rescale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_data_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;validation_generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;validation_data_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# fine-tune the model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;samples_per_epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_train_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validation_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nb_val_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_validation_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fine_tuning_weights_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975&quot;&gt;keras 이진 분류 fine tuning 샘플 코드&lt;/a&gt;와 차이점을 살펴보면,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;top model의 dense를 클래스 숫자만큼 설정하고, activation function을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt;에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;softmax&lt;/code&gt;로 변경&lt;/li&gt;
  &lt;li&gt;model의 loss 함수를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categorical_crossentropy&lt;/code&gt;으로 변경&lt;/li&gt;
  &lt;li&gt;ImageDataGenerator를 이용하여 보다 다양한 이미지 증가&lt;/li&gt;
  &lt;li&gt;class_mode를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary&lt;/code&gt;에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categorical&lt;/code&gt;로 변경&lt;/li&gt;
  &lt;li&gt;fine tuning 된 weights를 저장&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;우선, activation function은 다중 클래스의 결과값을 나타내야 하기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;softmax&lt;/code&gt;로 변경하였다.&lt;/p&gt;

&lt;p&gt;또한, 다양한 이미지를 확보하여 학습을 진행하기 위해 ImageDataGenerator의 다양한 옵션을 활용하였고, 다중 클래스에 대한 결과 값을 얻기 위해 loss 함수와 class_mode 설정 값을 변경하였다.&lt;/p&gt;

&lt;p&gt;위의 코드를 참고하여 fine tuning을 진행하면, 기존 학습과는 다르게 learning rate를 조절하여 굉장히 느리게 학습되는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;그렇기 때문에 epoch 횟수를 충분히 두어 최소의 loss를 갖는 포인트까지 학습해야 한다.&lt;/p&gt;

&lt;p&gt;(위의 예에서는 훈련 예가 많아서 nb_epoch 횟수를 150회로 증가시켜 진행하였다.)&lt;/p&gt;

&lt;h2 id=&quot;학습-결과&quot;&gt;학습 결과&lt;/h2&gt;

&lt;p&gt;위의 코드를 토대로 진행한 학습 조건과 결과물은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;클래스 갯수: 5&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;훈련 예: 2000 * 5&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 예: 500 * 5&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;클래스 별 정확도&lt;/p&gt;

    &lt;p&gt;A: 0.826531
 B: 0.970954
 C: 0.816832
 D: 0.796530
 E: 0.731481&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;일단, 기본적인 정확도를 가진 분류기를 학습했으니, 지속적으로 문제점을 찾아 개선하도록 하자.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">이 글은 이전 글인 keras를 이용한 다중 클래스 이미지 분류에 이어서 작성되었다.</summary></entry><entry><title type="html">keras를 이용한 다중 클래스 이미지 분류(1/2)</title><link href="http://localhost:4000/2017/01/04/01.html" rel="alternate" type="text/html" title="keras를 이용한 다중 클래스 이미지 분류(1/2)" /><published>2017-01-04T17:32:00+09:00</published><updated>2017-01-04T17:32:00+09:00</updated><id>http://localhost:4000/2017/01/04/01</id><content type="html" xml:base="http://localhost:4000/2017/01/04/01.html">&lt;p&gt;이 글은 이전 글인 &lt;a href=&quot;http://localhost:4000/2017/01/01/01.html&quot;&gt;keras를 이용한 이미지 이진 분류&lt;/a&gt;를 활용하여 작성하였다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:4000/2017/01/01/01.html&quot;&gt;keras를 이용한 이미지 이진 분류&lt;/a&gt;의 내용을 간략하게 상기시키면, 다음 3가지 방법을 토대로 적은 수의 이미지를 이용하여 이미지 분류를 위한 학습을 진행하였다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;이미지 증가&lt;/li&gt;
  &lt;li&gt;기 학습된 모델의 feature 활용&lt;/li&gt;
  &lt;li&gt;fine tuning&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 중 기 학습된 모델의 feature 활용과 fine tuning을 이용하여, 여러 개의 클래스를 가진 이미지들을 분류하는 작업을 진행해보고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;학습-및-검증-데이터-검수&quot;&gt;학습 및 검증 데이터 검수&lt;/h2&gt;

&lt;p&gt;본격적인 학습에 앞서, 훈련과 검증이 사용될 이미지를 검수하는 작업을 진행해야 한다.&lt;/p&gt;

&lt;p&gt;교사학습의 특성상 훈련 예는 불순물 없이 올바른 훈련 예만 제공되는 것이 좋기 때문이다.&lt;/p&gt;

&lt;p&gt;이를 위해 훈련 예를 검수하는 작업은 필수이다.&lt;/p&gt;

&lt;h2 id=&quot;기-학습된-모델의-feature-활용&quot;&gt;기 학습된 모델의 feature 활용&lt;/h2&gt;

&lt;p&gt;우선, 기 학습된 모델을 확보하기 위해 아래의 링크에서 VGG16 모델의 학습된 weights를 다운로드 받는다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3&quot;&gt;VGG16 모델 다운로드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그 후, 아래의 함수를 이용하여 같이 VGG16 모델 bottleneck feature를 저장한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;save_bottlebeck_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;                                                 
    &lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rescale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# build the VGG16 network
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                                                                   
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                                                                                
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                                                                                
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                                                                                
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Convolution2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Model weights not found (see &quot;weights_path&quot; variable in script).'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h5py&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nb_layers'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# we don't look at the last (fully-connected) layers in the savefile
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'layer_{}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'param_{}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nb_params'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Model loaded.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                                                                                
    &lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;train_data_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &amp;lt;= batch 사이즈 조정
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &amp;lt;= 다중 클래스 분류를 위해 클래스 모드 변경
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bottleneck_features_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb_train_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_train.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bottleneck_features_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                                                                                
    &lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;validation_data_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &amp;lt;= batch 사이즈 조정
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &amp;lt;= 다중 클래스 분류를 위해 클래스 모드 변경
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bottleneck_features_validation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb_validation_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_validation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bottleneck_features_validation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;위의 코드를 간단히 살펴보자면, VGG16 모델 레이어와 동일한 모델을 정의하고, 정의된 모델에 기 학습된 weights를 로드한다.&lt;/p&gt;

&lt;p&gt;그 후, 훈련 예를 이용하여 bottleneck features를 저장한다.&lt;/p&gt;

&lt;p&gt;기존의 이미지 이진 분류와의 차이점은 generator 객체 생성 시 분류 모델을 지정하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class_mode&lt;/code&gt; 옵션을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary&lt;/code&gt;가 아닌 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categorical&lt;/code&gt;로 변경한 것이다.&lt;/p&gt;

&lt;p&gt;문서를 살펴보면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class_mode&lt;/code&gt; 옵션은 아래와 같이 3가지 중 1가지를 선택할 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categorical&lt;/code&gt;: one-hot으로 인코딩된 labels(2 dimensions)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary&lt;/code&gt;: binary labels(1 dimension)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparse&lt;/code&gt;: integer labels(1 dimension)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categorical&lt;/code&gt;을 선택한 이유는 우리가 이미지 분류 시 결과 값을 binary나 integer가 아닌 명시적인 클래스 값을 받고 싶기 때문이다.&lt;/p&gt;

&lt;p&gt;이렇게 위에서 추출된 bottleneck features를 이용하여, 아래와 같이 최상위 모델인 top_model을 생성하고 top_model을 먼저 학습시킨다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_top_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;                                                          
    &lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_train.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_labels_by_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_validation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_labels_by_category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sgd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_model_weights_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;기존 코드와 달라진 중 하나는, train_labels, validation_labels을 구할 때 훈련 예와 검증 예의 갯수가 정해져있어 2등분해서 썼었지만, 위의 코드에서는 훈련 예와 검증 예의 갯수가 정해져 있지 않기 때문에 직접 기입해야 한다는 것이다.&lt;/p&gt;

&lt;p&gt;make_labels_by_category 함수에서는 각 폴더에 존재하는 훈련 예와 검증 예의 갯수를 불러와서 numpy array 형태로 만들어주는 역할을 한다.&lt;/p&gt;

&lt;p&gt;예를 들어, ‘A’, ‘B’, ‘C’의 카테고리가 있을 경우, ‘A’가 1000개, ‘B’가 2000개, ‘C’가 500개라면, labels = np.array([‘A’] * 1000 + [‘B’] * 2000 + [‘C’] * 500)로 구성되어질 것이다.&lt;/p&gt;

&lt;p&gt;당연히, labels 갯수가 data 갯수와 일치하지 않으면 학습이 진행되지 않는다.&lt;/p&gt;

&lt;p&gt;(&lt;del&gt;&lt;span style=&quot;color: grey&quot;&gt;너무 뻔한 소리지만 나는 왜 학습이 진행이 안되나 한참을 헤맸으므로 혹시 몰라서…&lt;/span&gt;&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;이렇게 생성된 labels값을 to_categorical 함수를 이용하여 multi dimension의 카테고리 labels 값을 가지게 된다.&lt;/p&gt;

&lt;p&gt;(&lt;del&gt;&lt;span style=&quot;color: grey&quot;&gt;궁금하면 shape 속성을 print해보면 어떤 형태인지 알 수 있을 것이다.&lt;/span&gt;&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;그리고, 또 다른 차이점은 top_model의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;activation function&lt;/code&gt; 옵션이 변경된 것이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense&lt;/code&gt;는 레이어의 밀집도를 나타내는 것으로 최종 output의 형태가 각 클래스의 확률로 표현되기 위해 클래스 갯수만큼의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense&lt;/code&gt;를 설정하였다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;activation function&lt;/code&gt; 옵션은 기존에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sigmoid&lt;/code&gt; 함수를 사용했는데,(&lt;del&gt;&lt;span style=&quot;color: grey&quot;&gt;binary 분류였으니까 당연히…&lt;/span&gt;&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;이 예제에서는 다중 클래스 분류를 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;softmax&lt;/code&gt; 함수로 변경하였다.&lt;/p&gt;

&lt;p&gt;이렇게 학습된 모델은 fine tuning을 거쳐 이미지 분류기 역할을 하게 된다.&lt;/p&gt;

&lt;p&gt;fine tuning을 진행하는 예제는 다음 포스트에 진행하기로 한다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">이 글은 이전 글인 keras를 이용한 이미지 이진 분류를 활용하여 작성하였다.</summary></entry><entry><title type="html">GPU를 인식하지 못하는 문제 해결</title><link href="http://localhost:4000/2017/01/02/01.html" rel="alternate" type="text/html" title="GPU를 인식하지 못하는 문제 해결" /><published>2017-01-02T16:20:00+09:00</published><updated>2017-01-02T16:20:00+09:00</updated><id>http://localhost:4000/2017/01/02/01</id><content type="html" xml:base="http://localhost:4000/2017/01/02/01.html">&lt;p&gt;이 포스트에서는 tensorflow와 keras를 이용하여 이미지를 분류할 때, GPU를 인식하지 못하는 문제에 대해 기술하려고 한다.&lt;/p&gt;

&lt;p&gt;이 포스트에서 다루는 문제는 필자가 경험한 내용만을 다루고 있으므로 참고바란다.&lt;/p&gt;

&lt;h2 id=&quot;gpu를-인식하지-못하는-문제&quot;&gt;GPU를 인식하지 못하는 문제&lt;/h2&gt;

&lt;p&gt;우선, 이전 포스트인 &lt;a href=&quot;http://localhost:4000/2016/12/29/01.html&quot;&gt;딥러닝 테스트용 PC 설치 및 설정&lt;/a&gt;을 선행한 후, terminal에서 아래와 같은 명령어를 입력해보도록 하자.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;nvidia-smi&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;그 결과가 아래와 같이 나온다면 GPU 드라이버 설치는 정상적으로 이루어진 것이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|&lt;span class=&quot;o&quot;&gt;===============================&lt;/span&gt;+&lt;span class=&quot;o&quot;&gt;======================&lt;/span&gt;+&lt;span class=&quot;o&quot;&gt;======================&lt;/span&gt;|
|   0  GeForce GTX 1080    Off  | 0000:01:00.0     Off |                  N/A |
|  0%   30C    P8    13W / 198W |   7745MiB /  8111MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|&lt;span class=&quot;o&quot;&gt;=============================================================================&lt;/span&gt;|
|    0     19846    C   .../versions/2.7.13/envs/keras/bin/python2.7  7743MiB |
+-----------------------------------------------------------------------------+&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;만약, 명령어를 인식하지 못한다거나 문제가 발생한다면 GPU 드라이버 설치에 문제가 있는 것이다.&lt;/p&gt;

&lt;p&gt;이 경우, 아래의 GPU 드라이버 설치 가이드 및 tensorflow os별 설치 방법을 참고하면 해결이 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/wangruohui/df039f0dc434d6486f5d4d098aa52d07&quot;&gt;GPU 드라이버 설치 가이드&lt;/a&gt;, &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md&quot;&gt;tensorflow os별 설치 방법&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;대체적으로 keras 이용시 문제가 되었던 부분은,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;nvidia GPU 드라이버의 잘못된 설치&lt;/li&gt;
  &lt;li&gt;nvidia-modprobe의 미활용(nvidia-modprobe는 머신이 실행될 때마다 자동적으로 NVIDIA 커널 모듈을 불러오고, NVIDIA 캐릭터 장치를 생성하는 역할을 한다.)&lt;/li&gt;
  &lt;li&gt;CUDA_HOME, LD_LIBRARY_PATH 등 cuda, cudnn 경로 환경 변수 미적용&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;정도였던 것 같다.&lt;/p&gt;

&lt;p&gt;추후, 새로운 문제가 발견되어 해결한다면 업데이트를 하도록 하겠다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">이 포스트에서는 tensorflow와 keras를 이용하여 이미지를 분류할 때, GPU를 인식하지 못하는 문제에 대해 기술하려고 한다.</summary></entry><entry><title type="html">keras를 이용한 이미지 이진 분류</title><link href="http://localhost:4000/2017/01/01/01.html" rel="alternate" type="text/html" title="keras를 이용한 이미지 이진 분류" /><published>2017-01-01T12:03:00+09:00</published><updated>2017-01-01T12:03:00+09:00</updated><id>http://localhost:4000/2017/01/01/01</id><content type="html" xml:base="http://localhost:4000/2017/01/01/01.html">&lt;p&gt;이번 포스트에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;keras&lt;/code&gt;를 이용한 이미지 이진 분류 테스트를 진행해보고자 한다.&lt;/p&gt;

&lt;p&gt;(이 포스트는 &lt;a href=&quot;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&quot;&gt;keras 이미지 분류 모델 생성 블로그&lt;/a&gt;를 참고하여 작성하였다.)&lt;/p&gt;

&lt;p&gt;자동 분류 작업을 위해서는 이전 포스트인 &lt;a href=&quot;http://localhost:4000/2016/12/29/01.html&quot;&gt;딥러닝 테스트용 PC 설치 및 설정&lt;/a&gt;을 선행해야 한다.&lt;/p&gt;

&lt;p&gt;선행을 완료했다면, &lt;a href=&quot;https://keras.io/#installation&quot;&gt;keras 설치 공식 홈페이지&lt;/a&gt;에 따라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numpy&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyyaml&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h5py&lt;/code&gt;등을 설치하도록 한다.&lt;/p&gt;

&lt;p&gt;(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cudnn&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tensorflow&lt;/code&gt;는 위에 언급한 선행 설치를 올바르게 했다면 설치가 되었을 것이다.)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyyaml&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h5py&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;pip를 이용하여 keras를 설치하도록 하자.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;keras까지 설치가 끝났다면, 아래와 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.keras/keras.json&lt;/code&gt; 파일의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image_dim_ordering&lt;/code&gt;항목을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;th&lt;/code&gt;로 수정한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;image_dim_ordering&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;th&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#=&amp;gt; tf를 th로 변경&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;epsilon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                                                              
    &lt;span class=&quot;s2&quot;&gt;&quot;floatx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;float32&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                                                           
    &lt;span class=&quot;s2&quot;&gt;&quot;backend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;tensorflow&quot;&lt;/span&gt;                                                        
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image_dim_ordering&lt;/code&gt;은 이미지의 3차원 dimension을 표현할 때 각 값의 순서를 정하는 옵션이다.&lt;/p&gt;

&lt;p&gt;위 블로그의 예제는 (pixel value, x dimension, y dimension)의 순서대로 구성되어 있어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;th&lt;/code&gt;로 변경하면 된다.&lt;/p&gt;

&lt;p&gt;그리고 이미지 처리를 위해 아래와 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pillow&lt;/code&gt; 라이브러리를 설치하도록 한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libjpeg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zlib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libpng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pillow&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;이제 본격적으로 이미지 분류를 진행해보도록 하자.&lt;/p&gt;

&lt;p&gt;해당 블로그에서 설명하고 있는 이미지 분류 성능을 높이는 과정은 크게 3단계로 나뉜다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;이미지-증가image-augmentation&quot;&gt;이미지 증가(Image Augmentation)&lt;/h2&gt;

&lt;p&gt;이미지 증가는 적은 수의 훈련 이미지를 임의로 변환함으로써 다양한 훈련 이미지를 확보한다.&lt;/p&gt;

&lt;p&gt;이렇게 확보된 훈련 이미지를 학습에 이용함으로써 기계 학습에서 항상 언급되는 overfit 문제를 보완할 수 있다.&lt;/p&gt;

&lt;p&gt;알려진대로 딥러닝은 엄청나게 많은 훈련 예를 필요로 하지만, 이미지 증가를 이용하면 어느정도 훈련 예를 보장할 수 있다.&lt;/p&gt;

&lt;p&gt;keras의 ImageDataGenerator 클래스를 이용하면, 아래와 같이 회전 정도, 상하좌우 이동, 경사도, 줌 레벨, 좌우 반전 등의 다양한 옵션을 통한 이미지 증가를 할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.preprocessing.image&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rotation_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;width_shift_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;height_shift_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rescale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shear_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zoom_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;horizontal_flip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fill_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nearest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;샘플 코드는 아래 링크를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d&quot;&gt;keras 이미지 증가 샘플 코드&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;미리-학습된-모델의-bottleneck-feature를-이용&quot;&gt;미리 학습된 모델의 bottleneck feature를 이용&lt;/h2&gt;

&lt;p&gt;두 번째 방법으로는 기존에 학습한 모델의 일부 feature들을 이용하여 학습을 진행하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&quot;&gt;keras 이미지 분류 모델 생성 블로그&lt;/a&gt;에서는 VGG16 모델의 bottleneck feature를 이용하여 학습을 진행한다.&lt;/p&gt;

&lt;p&gt;VGG16은 ILSVRC-2014 대회에서 VGG팀이 사용한 16개의 layer로 구성된 모델로써, 수많은 카테고리의 다양한 이미지를 학습한 모델이다.&lt;/p&gt;

&lt;p&gt;VGG16은 아래 링크에서 다운로드 받으면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3&quot;&gt;VGG16 모델 다운로드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;VGG16 모델을 다운로드 받은 후, 아래와 같은 코드로 bottleneck feature를 추출한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;'data/train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the predict_generator method returns the output of a model, given
# a generator that yields batches of numpy data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bottleneck_features_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# save the output as a Numpy array
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_train.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bottleneck_features_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datagen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow_from_directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;'data/validation'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bottleneck_features_validation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_validation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bottleneck_features_validation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;이렇게 추출된 bottleneck feature를 토대로 아래와 같이 fully-connected 모델을 훈련한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_train.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the features were saved in order, so recreating the labels is easy
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_features_validation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmsprop'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'binary_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;nb_epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bottleneck_fc_model.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;위와 같이 훈련된 모델의 weights를 이용하여 predict를 해보면, 약 90%에 가까운 정확도를 보인다.(&lt;span style=&quot;color:grey&quot;&gt;&lt;del&gt;88%인건 함정&lt;/del&gt;&lt;/span&gt;)&lt;/p&gt;

&lt;p&gt;샘플 코드는 아래의 링크를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069&quot;&gt;keras 기 학습된 모델 이용 샘플 코드&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;fine-tuning&quot;&gt;Fine tuning&lt;/h2&gt;

&lt;p&gt;마지막으로 fine tuning은 미리 학습된 모델의 마지막 레벨 conv block의 weights를 학습하되, 새로운 훈련 예를 이용하여 weigits를 조금씩 갱신하는 방법이다.&lt;/p&gt;

&lt;p&gt;이 과정은 총 3단계 나뉘어 진행할 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;VGG16모델(기 학습된 모델)과 weights를 불러와서 초기화한다.&lt;/li&gt;
  &lt;li&gt;2단계에서 학습된 fully-connected 모델을 top model로 붙이고, weights를 불러온다.&lt;/li&gt;
  &lt;li&gt;생성된 모델의 마지막 conv block에 새로운 훈련 예로 학습&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;fine tuning을 위한 주의사항은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;모든 레이어는 기 학습이 되어있어야 한다.&lt;/li&gt;
  &lt;li&gt;전체 레이어에 대해 fine tuning을 진행하는 것이 아니라, 마지막 conv block에만 진행한다.&lt;/li&gt;
  &lt;li&gt;fine tuning에는 RMSProp과 같은 adaptive optimizer보다 SGD optimizer같은 optimizer가 선호된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;모든 레이어가 기 학습되어야 하는 이유는 학습도중 급격한 weights 변화로 학습 결과가 망가지는 것을 방지하기 위함이고, 마지막 conv block에만 fine tuning을 진행하는 이유는 overfitting 문제를 방지하기 위함이다.&lt;/p&gt;

&lt;p&gt;위와 같이 fine tuning을 진행하면, 약 95%에 가까운 정확도를 보인다. 놀랍지 않은가…&lt;/p&gt;

&lt;p&gt;샘플 코드는 아래의 링크를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975&quot;&gt;keras fine tuning 샘플 코드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이렇게 &lt;a href=&quot;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&quot;&gt;keras 이미지 분류 모델 생성 블로그&lt;/a&gt;를 참고하여, 소량의 훈련 예로도 훌륭한 성능을 가지는 이진 이미지 분류기를 만들어보았다.&lt;/p&gt;

&lt;p&gt;이후에는, 다양한 카테고리를 분류할 수 있는 분류기를 만들어보고자 한다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">이번 포스트에는 keras를 이용한 이미지 이진 분류 테스트를 진행해보고자 한다.</summary></entry><entry><title type="html">딥러닝 테스트용 PC 설치 및 설정</title><link href="http://localhost:4000/2016/12/29/01.html" rel="alternate" type="text/html" title="딥러닝 테스트용 PC 설치 및 설정" /><published>2016-12-29T15:42:00+09:00</published><updated>2016-12-29T15:42:00+09:00</updated><id>http://localhost:4000/2016/12/29/01</id><content type="html" xml:base="http://localhost:4000/2016/12/29/01.html">&lt;p&gt;이번에 사내프로젝트의 일환으로 이미지 분석 및 처리를 위한 딥러닝 테스트 PC를 구매하였다.&lt;/p&gt;

&lt;p&gt;이 포스트는 딥러닝 테스트용으로 구매한 PC의 기본적인 설정을 하는 일련의 작업에 대해 기술하고자 한다.&lt;/p&gt;

&lt;p&gt;이번에 구매한 PC의 주요한 하드웨어 스펙은 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/2016-12-29-01-01.png&quot; alt=&quot;PC 하드웨어 스펙&quot; /&gt;&lt;/p&gt;

&lt;p&gt;딥러닝용 PC 구매에서 중요한 부분은 GPU, 파워, 케이스라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;자세한 내용은 관련 블로그를 참고하면 될 것 같다.
&lt;del&gt;&lt;a href=&quot;http://tmmse.xyz/gpureccom/&quot;&gt;관련 블로그&lt;/a&gt;&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&quot;os-설치&quot;&gt;OS 설치&lt;/h2&gt;

&lt;p&gt;우선 OS는 Linux 계열 중 CentOS 7을 설치하기로 했다.(이 중 mininal 버젼 설치)&lt;/p&gt;

&lt;p&gt;별 다른 이유는 없었고 Windows는 개발용으로 적합하지 않았고, 다른 개발 서버와 서버 계열을 맞추는게 여러모로 편했기 때문이다.&lt;/p&gt;

&lt;p&gt;부팅 디스크를 만드는 것은 아래의 블로그를 참고했다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.definejava.net/61&quot;&gt;부팅 디스크 참고 블로그&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;블로그에서 언급된 프로그램 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;win32diskimagek&lt;/code&gt;를 이용하여 부팅디스크를 만들었고, BIOS 설정에서 시동디스크를 변경하여 설치를 시작했다.&lt;/p&gt;

&lt;p&gt;설치가 잘 되는 듯 하다가 모니터가 갑자기 먹통이 된다….&lt;/p&gt;

&lt;p&gt;정신이 아득하다…..&lt;/p&gt;

&lt;p&gt;검색해보니, 구매한 gtx 1080의 Driver가 설치가 되지 않아 모니터가 IO를 받을 수 없는 문제라 한다.&lt;/p&gt;

&lt;p&gt;해결책은 원격 접속을 통해 Driver를 설치하란다..(&lt;del&gt;저기 뭐 OS가 설치완료되어야 원격 접속을 하지요…&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;정신을 차려보자.&lt;/p&gt;

&lt;p&gt;일단, OS 설치를 완료하고 그래픽 카드 Driver를 설치하면 되겠지라는 마음으로 다음과 같이 진행을 했다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;그래픽 카드 DVI에 연결되어 있는 모니터 케이블을 메인보드 DVI에 연결&lt;/li&gt;
  &lt;li&gt;BIOS에서 GPU 선택 옵션을 AUTO로 변경&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;설치를 다시 시작한다. 설치가 잘된다.&lt;/p&gt;

&lt;p&gt;네트워크, 계정 정보 등 여러가지 옵션들을 내가 원하는대로 정한 후, 설치를 완료하도록 하자.&lt;/p&gt;

&lt;h2 id=&quot;기본-설정&quot;&gt;기본 설정&lt;/h2&gt;

&lt;p&gt;CentOS 7을 설치하고 나서, 기본적인 기능을 위해 다음과 같은 스크립트를 실행시켰다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;c1&quot;&gt;#!/bin/bash                                                                     &lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;                                                                 
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;                                                      
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enhanced&lt;/span&gt;                                                   
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;git&lt;/span&gt;                                                            
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt;       &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;vim을 사용하지 않는 사용자라면 vim-enhanced를 설치하지 않아도 된다.&lt;/p&gt;

&lt;h2 id=&quot;그래픽-드라이버-설치&quot;&gt;그래픽 드라이버 설치&lt;/h2&gt;

&lt;p&gt;그래픽 드라이버 설치는 아래의 블로그를 참고하여 설치하였다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://sunyzero.tistory.com/218&quot;&gt;그래픽 드라이버 설치 블로그&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;설치를 위해 필요한 전처리를 해주고 아래의 NVIDIA 공식 홈페이지를 가서, 자신의 OS와 GPU에 맞는 옵션을 선택하여 드라이버를 다운로드한다.&lt;/p&gt;

&lt;p&gt;(다운로드 링크가 직접적으로 제공되지 않아, 직접 다운로드 받은 후 파일을 scp로 이동시켰다.)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nvidia.co.kr/Download/index.aspx?lang=kr&quot;&gt;NVIDIA 드라이버 공식 홈페이지&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;다운로드 받은 run 파일을 다음과 같이 실행시키고 안내에 따라 설치를 완료하면 된다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;bash&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;NVIDIA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x86&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;375.26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;cuda-및-cudnn-설치&quot;&gt;cuda 및 cudnn 설치&lt;/h2&gt;

&lt;p&gt;cuda는 GPU에서 수행하는 일련의 알고리즘을 여러 표준 언어를 사용해서 작성할 수 있도록 하는 기술이다.&lt;/p&gt;

&lt;p&gt;우리가 비싼 돈을 들여 GPU를 구매한 이유도 바로 이 기술 때문인데, 이 기술이 딥러닝에 필요한 엄청난 양의 연산을 GPU에서 병렬 연산처리할 수 있도록 지원해주기 때문이다.&lt;/p&gt;

&lt;p&gt;아래의 공식 홈페이지에서 안내하는대로 설치를 진행하면 cuda 설치를 완료할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation&quot;&gt;cuda 설치 안내 홈페이지&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cuda 설치파일을 받는 방법은 다양한 방법이 존재하는데, 아래 홈페이지에서 자신의 옵션에 맞게 선택하여 진행하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-downloads&quot;&gt;cuda 다운로드 공식 홈페이지&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cuda 설치가 완료되면 cudnn을 설치하도록 한다.&lt;/p&gt;

&lt;p&gt;cudnn은 딥러닝을 위해 고안된 GPU 특화 라이브러리로써, 대다수의 딥러닝 관련 프레임워크(Caffe, Tensorflow, Theano 등)들은 cudnn을 지원한다.&lt;/p&gt;

&lt;p&gt;cudnn은 아래의 공식 홈페이지에서 다운로드 받을 수 있는데, 꽤 많은 정보를 입력해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;cudnn 다운로드 공식 홈페이지&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;다운로드 받은 후, 압축을 풀고 아래와 같이 관련 파일을 cuda 설치 path에 복사한다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lib64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*&lt;/span&gt; &lt;span class=&quot;sr&quot;&gt;/usr/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/* /us&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;pyenv-설치&quot;&gt;pyenv 설치&lt;/h2&gt;

&lt;p&gt;pyenv는 다양한 버젼, 환경의 python을 쉽게 설치할 수 있고, virtualenv과 같이 사용하여 프로그램 실행에 필요한 실행 환경을 시스템 의존성과 관계없이 구축할 수 있다는 장점이 있다.&lt;/p&gt;

&lt;p&gt;이를 위해 아래와 같이 pyenv를 설치했다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;c1&quot;&gt;#!/bin/bash                                                                        &lt;/span&gt;
                                                                                   
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patch&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;openssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zlib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bzip2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt;
                                                                                   
&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:/&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yyuu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/.pyenv                               
git clone https:/&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yyuu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyenv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;virtualenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/.pyenv/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyenv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;virtualenv&lt;/span&gt;
                                                                                   
&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/.bash_profile                         
echo 'export PATH=&quot;$PYENV_ROOT/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;vg&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;' &amp;gt;&amp;gt; ~/.bash_profile                      
                                                                                   
echo 'eval &quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyenv&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;' &amp;gt;&amp;gt; ~/.bash_profile                                   
echo 'eval &quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyenv&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;virtualenv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;' &amp;gt;&amp;gt; ~/.bash_profile                        
                                                                                   
exec $SHELL                                                                        
                                                                                   
source ~/.bash_profile   &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;tensorflow-설치&quot;&gt;tensorflow 설치&lt;/h2&gt;

&lt;p&gt;tensorflow는 구글에서 만든 오픈소스 프로젝트로써, data flow graph를 이용하여 수치 계산을 용이하게 해주는 라이브러리이다.&lt;/p&gt;

&lt;p&gt;일반적으로, 인공지능 분야에서 많이 사용하고 있으며, 파이썬을 API 형태로 제공된다.&lt;/p&gt;

&lt;p&gt;tensorflow는 파이썬 패키지 매니저인 pip를 이용하여 설치할 수 있으나, 최신 버젼 등록이 안되어있을 수도 있기 때문에, 아래와 같이 직접 설치를 진행했다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#virtualenv-installation&quot;&gt;virtualenv를 이용한 tensorflow 설치&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-cuda-연동-확인&quot;&gt;tensorflow cuda 연동 확인&lt;/h2&gt;

&lt;p&gt;위의 과정들을 거치면 GPU를 활용하여 tensorflow를 이용할 준비가 되었다고 할 수 있다.&lt;/p&gt;

&lt;p&gt;tensorflow에서 cuda, cudnn을 잘 열수 있는지 확인하기 위해서는 아래의 명령어를 입력해보면 된다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;import tensorflow&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;필자의 경우, 아래와 같은 메시지가 출력되었는데&lt;/p&gt;

&lt;p&gt;이는 tensorflow에서 cuda, cudnn을 정상적으로 이용할 수 없다는 것이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;108&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcublas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;7.0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;108&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcudnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;108&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcufft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;7.0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;102&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Couldn&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;이를 해결하기 위해서는, 아래의 커맨드를 입력해서 cuda의 설치경로를 잡아준다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/.bash_profile
echo 'export LD_LIBRARY_PATH=/us&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;8.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib64&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/.bash_profile&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;수정 후, 다시 tensorflow를 실행하면 아래와 같은 처리메시지가 나올 것이다.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcublas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcudnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcufft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dso_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successfully&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opened&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;libcurand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locally&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;다음 포스트에는 keras를 이용하여, 이미지 카테고리를 분류하는 작업을 진행하고자 한다.&lt;/p&gt;</content><author><name>lamttic</name></author><summary type="html">이번에 사내프로젝트의 일환으로 이미지 분석 및 처리를 위한 딥러닝 테스트 PC를 구매하였다.</summary></entry></feed>